{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ssd_make_list_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# voc2012 dataset download"
      ],
      "metadata": {
        "id": "_PnudA8Uomac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tarfile"
      ],
      "metadata": {
        "id": "nxnQP5iZk_N4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "m2MAiNzdoGfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/MyDrive/Image/data/\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)"
      ],
      "metadata": {
        "id": "vJDq6aMhk_BU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_dir = \"/content/drive/MyDrive/Image/weight/\"\n",
        "if not os.path.exists(weights_dir):\n",
        "    os.mkdir(weights_dir)"
      ],
      "metadata": {
        "id": "03wFKEn7lDT_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\"\n",
        "target_path = os.path.join(data_dir, \"VOCtrainval_11-May-2012.tar\") \n",
        "\n",
        "if not os.path.exists(target_path):\n",
        "    urllib.request.urlretrieve(url, target_path)\n",
        "    \n",
        "    tar = tarfile.TarFile(target_path) \n",
        "    tar.extractall(data_dir)  \n",
        "    tar.close() \n",
        "    "
      ],
      "metadata": {
        "id": "gsB0mbo-lDKg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MIT License\n",
        "# Copyright (c) 2017 Max deGroot, Ellis Brown\n",
        "# https://github.com/amdegroot/ssd.pytorch\n",
        "    \n",
        "url = \"https://s3.amazonaws.com/amdegroot-models/vgg16_reducedfc.pth\"\n",
        "target_path = os.path.join(weights_dir, \"vgg16_reducedfc.pth\") \n",
        "\n",
        "if not os.path.exists(target_path):\n",
        "    urllib.request.urlretrieve(url, target_path)"
      ],
      "metadata": {
        "id": "3N_zWn64lLUX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MIT License\n",
        "# Copyright (c) 2017 Max deGroot, Ellis Brown\n",
        "# https://github.com/amdegroot/ssd.pytorch\n",
        "\n",
        "url = \"https://s3.amazonaws.com/amdegroot-models/ssd300_mAP_77.43_v2.pth\"\n",
        "target_path = os.path.join(weights_dir, \"ssd300_mAP_77.43_v2.pth\") \n",
        "\n",
        "if not os.path.exists(target_path):\n",
        "    urllib.request.urlretrieve(url, target_path)"
      ],
      "metadata": {
        "id": "DEKdORUtlPTz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s6BJKzlWkUZ4"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "import random\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)"
      ],
      "metadata": {
        "id": "9KmVShuEkZJu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data path list 작성\n",
        "\n",
        "- SSD dataset : Image classification data + annotation data \n",
        "> data annotation : dataset에 메터 데이터를 추가하는 작업 \n",
        "> : '태그'(주석) 형식으로 이미지, 텍스트, 비디오 등 거의 모든 데이터에 추가가 가능하다. -> 한국에서는 라벨링이라는 표현으로 많이쓴인다.\n",
        "> 즉, 인공지능이 데이터의 내용을 이해할수 있도록 주석을 달아주는 작업이라고 보면된다.\n",
        "\n",
        "- annotation data를 사용하는 이유는 annotation technique중 하나인 BBox(Bounding Box)를 사용하기 때문이다.(대표적으로 , BBox, polygon,cuboid, semantic segmentation ..등 이 있다.)\n",
        "\n",
        "---\n",
        "\n",
        "- SSD에서는 Image data와 함깨 annotation data도 같이 처리해야한다.\n",
        "> : image 정보가 바뀌면 BBox의 정보도 함께 변경해야한다. \n",
        "\n"
      ],
      "metadata": {
        "id": "xUXVLOiCo0tA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_datapath_list(rootpath):\n",
        "\n",
        "    imgpath_template = osp.join(rootpath, 'JPEGImages', '%s.jpg')\n",
        "    annopath_template = osp.join(rootpath, 'Annotations', '%s.xml')\n",
        "\n",
        "    train_id_names = osp.join(rootpath + 'ImageSets/Main/train.txt')\n",
        "    val_id_names = osp.join(rootpath + 'ImageSets/Main/val.txt')\n",
        "\n",
        "    # 훈련 리스트\n",
        "    train_img_list = list()\n",
        "    train_anno_list = list()\n",
        "\n",
        "    for line in open(train_id_names):\n",
        "        file_id = line.strip()  # 공백, 줄바꿈 제거\n",
        "        img_path = (imgpath_template % file_id)  # 화상 경로\n",
        "        anno_path = (annopath_template % file_id)  # 어노테이션 경로\n",
        "        train_img_list.append(img_path)  \n",
        "        train_anno_list.append(anno_path)  \n",
        "\n",
        "    # 검증 리스트\n",
        "    val_img_list = list()\n",
        "    val_anno_list = list()\n",
        "\n",
        "    for line in open(val_id_names):\n",
        "        file_id = line.strip()  # 공백, 줄바꿈 제거\n",
        "        img_path = (imgpath_template % file_id)  # 화상 경로\n",
        "        anno_path = (annopath_template % file_id) # 어노테이션 경로 \n",
        "        val_img_list.append(img_path)  \n",
        "        val_anno_list.append(anno_path)  \n",
        "\n",
        "    return train_img_list, train_anno_list, val_img_list, val_anno_list"
      ],
      "metadata": {
        "id": "fC_NF3MukbbL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rootpath = \"/content/drive/MyDrive/Image/data/VOCdevkit/VOC2012/\"\n",
        "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n",
        "    rootpath)\n",
        "\n",
        "print(train_img_list[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfW2Yn1hkk0t",
        "outputId": "d31bb806-f391-4065-e908-91d143071d98"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Image/data/VOCdevkit/VOC2012/JPEGImages/2008_000008.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XML to list (annotaion data)"
      ],
      "metadata": {
        "id": "wU4DabEFxLzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Anno_xml2list(object):\n",
        "    \n",
        "    def __init__(self, classes):\n",
        "        self.classes = classes\n",
        "\n",
        "    def __call__(self, xml_path, width, height):\n",
        "        ret = []\n",
        "        xml = ET.parse(xml_path).getroot()\n",
        "\n",
        "        for obj in xml.iter('object'):\n",
        "            difficult = int(obj.find('difficult').text)\n",
        "            if difficult == 1:\n",
        "                continue\n",
        "\n",
        "            bndbox = []\n",
        "            name = obj.find('name').text.lower().strip()  \n",
        "            bbox = obj.find('bndbox')  \n",
        "\n",
        "            pts = ['xmin', 'ymin', 'xmax', 'ymax']\n",
        "\n",
        "            for pt in (pts):\n",
        "                cur_pixel = int(bbox.find(pt).text) - 1\n",
        "\n",
        "                if pt == 'xmin' or pt == 'xmax':  \n",
        "                    cur_pixel /= width\n",
        "                else:  \n",
        "                    cur_pixel /= height\n",
        "\n",
        "                bndbox.append(cur_pixel)\n",
        "\n",
        "            label_idx = self.classes.index(name)\n",
        "            bndbox.append(label_idx)\n",
        "            ret += [bndbox]\n",
        "\n",
        "        return np.array(ret)  # [[xmin, ymin, xmax, ymax, label_ind], ... ]"
      ],
      "metadata": {
        "id": "uhMrK5nckpXN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
        "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
        "               'cow', 'diningtable', 'dog', 'horse',\n",
        "               'motorbike', 'person', 'pottedplant',\n",
        "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "\n",
        "transform_anno = Anno_xml2list(voc_classes)\n",
        "\n",
        "ind = 1\n",
        "image_file_path = val_img_list[ind]\n",
        "img = cv2.imread(image_file_path)  \n",
        "height, width, channels = img.shape  \n",
        "\n",
        "transform_anno(val_anno_list[ind], width, height)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lfd1z2Sp_-p",
        "outputId": "16de711e-4641-4280-b988-9f0ce6214f3b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.09      ,  0.03003003,  0.998     ,  0.996997  , 18.        ],\n",
              "       [ 0.122     ,  0.56756757,  0.164     ,  0.72672673, 14.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "- 만들면서 배우는 파이토치 딥러닝, 오가와 유타로 저, 박광수 옮김, 한빛미디어 (2021)"
      ],
      "metadata": {
        "id": "o7OfKq73yV2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FrG1gsjO1NgZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}