{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_basics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz030qZL5YYA"
      },
      "source": [
        "\n",
        "## 1. Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJdgzdML5FIo"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "61F6vqxO5sSP",
        "outputId": "54f36a97-40b5-4870-9ca5-f92a2380bcd5"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNiYqlS5561P",
        "outputId": "c599cbbc-ade7-4833-e677-8e042c2fab48"
      },
      "source": [
        "# Numpy\n",
        "a = np.zeros((5,5)) # 5x5 zero Matrix\n",
        "b = np.ones((5,5)) # 5x5 ones  Matrix\n",
        "c = np.random.rand(5,5) # 5x5 random Matrix \n",
        "\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "[[1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]]\n",
            "[[0.837048   0.60093064 0.57334265 0.33944183 0.6978507 ]\n",
            " [0.06567256 0.68372126 0.1320196  0.72863137 0.36563264]\n",
            " [0.94457699 0.00288996 0.4288324  0.98657529 0.14381706]\n",
            " [0.74250896 0.9064287  0.15484291 0.53133911 0.41739447]\n",
            " [0.78390429 0.14420735 0.39309681 0.32183039 0.91485756]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o7zNe-y6POo",
        "outputId": "73139a75-a628-4d4f-d3e0-ca4a4b4d4578"
      },
      "source": [
        "# Pytorch\n",
        "q = torch.zeros((5,5))\n",
        "p = torch.ones((5,5))\n",
        "r = torch.rand((5,5))\n",
        "\n",
        "print(q)\n",
        "print(p)\n",
        "print(r)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n",
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]])\n",
            "tensor([[0.0886, 0.7538, 0.6960, 0.6997, 0.8421],\n",
            "        [0.1442, 0.7614, 0.8007, 0.0600, 0.2722],\n",
            "        [0.3938, 0.1616, 0.8353, 0.1772, 0.2406],\n",
            "        [0.9120, 0.8453, 0.4606, 0.3511, 0.5998],\n",
            "        [0.6719, 0.0721, 0.8829, 0.9798, 0.5669]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIkBCGKR6n5W",
        "outputId": "a4033156-8401-4eb7-df16-d7e489132efc"
      },
      "source": [
        "s = torch.from_numpy(c)\n",
        "s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8370, 0.6009, 0.5733, 0.3394, 0.6979],\n",
              "        [0.0657, 0.6837, 0.1320, 0.7286, 0.3656],\n",
              "        [0.9446, 0.0029, 0.4288, 0.9866, 0.1438],\n",
              "        [0.7425, 0.9064, 0.1548, 0.5313, 0.4174],\n",
              "        [0.7839, 0.1442, 0.3931, 0.3218, 0.9149]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJt40qi4-_Gt",
        "outputId": "a0b7185f-dd2d-4a1f-f869-6388fed39152"
      },
      "source": [
        "s[0,0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8370, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOV-Ufec6xOZ",
        "outputId": "36f75d2d-a5d3-4df3-a0ff-179578082cae"
      },
      "source": [
        "s[0,0].item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8370479998707208"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrATCj107EKz",
        "outputId": "d6885d24-723b-4784-ef4b-4a4ce52ce3d9"
      },
      "source": [
        "s+r"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9257, 1.3548, 1.2693, 1.0391, 1.5400],\n",
              "        [0.2099, 1.4452, 0.9327, 0.7886, 0.6378],\n",
              "        [1.3384, 0.1645, 1.2642, 1.1638, 0.3844],\n",
              "        [1.6545, 1.7517, 0.6155, 0.8824, 1.0172],\n",
              "        [1.4558, 0.2163, 1.2760, 1.3017, 1.4818]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbrgObX67T2T",
        "outputId": "4fce4138-7586-4191-dfa8-692e46eb9698"
      },
      "source": [
        "(s+r).to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9257, 1.3548, 1.2693, 1.0391, 1.5400],\n",
              "        [0.2099, 1.4452, 0.9327, 0.7886, 0.6378],\n",
              "        [1.3384, 0.1645, 1.2642, 1.1638, 0.3844],\n",
              "        [1.6545, 1.7517, 0.6155, 0.8824, 1.0172],\n",
              "        [1.4558, 0.2163, 1.2760, 1.3017, 1.4818]], device='cuda:0',\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MO2BGUn7aQa",
        "outputId": "b2acd144-04dd-4dd5-d305-7dc819e31e0a"
      },
      "source": [
        "s.float()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8370, 0.6009, 0.5733, 0.3394, 0.6979],\n",
              "        [0.0657, 0.6837, 0.1320, 0.7286, 0.3656],\n",
              "        [0.9446, 0.0029, 0.4288, 0.9866, 0.1438],\n",
              "        [0.7425, 0.9064, 0.1548, 0.5313, 0.4174],\n",
              "        [0.7839, 0.1442, 0.3931, 0.3218, 0.9149]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNKfmP7j8HMB",
        "outputId": "1dffa22b-018c-4758-aa66-74f5ebf2b835"
      },
      "source": [
        "# float64 가 나오면  float을 붙여 바꿔줌\n",
        "(s+r).float().to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9257, 1.3548, 1.2693, 1.0391, 1.5400],\n",
              "        [0.2099, 1.4452, 0.9327, 0.7886, 0.6378],\n",
              "        [1.3384, 0.1645, 1.2642, 1.1638, 0.3844],\n",
              "        [1.6545, 1.7517, 0.6155, 0.8824, 1.0172],\n",
              "        [1.4558, 0.2163, 1.2760, 1.3017, 1.4818]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbwOqRvT8dzT"
      },
      "source": [
        "##   2.Linear Regression with Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPxZPUcC8TgB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f72fa949-966c-4f51-81f5-d76c5d3b2aad"
      },
      "source": [
        "# Data generation with hands\n",
        "x = torch.arange(0,1,0.1)\n",
        "y = 2*x -1 + torch.randn(len(x))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
              "        0.9000])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLfscA5882RA"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "gwpAn4-99CKs",
        "outputId": "e402cc84-fb45-42bc-9e03-6ed0b935da40"
      },
      "source": [
        "plt.plot(x,y,'.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd74d6bfcd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmFXj9ru9Irb"
      },
      "source": [
        "# For validation\n",
        "x_val = torch.arange(0,1,0.2)\n",
        "y_val = 2*x_val -1 + 0.1 *torch.randn(len(x_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "eaIgwos_9i7z",
        "outputId": "459de51d-f529-40c0-856c-13438bda3aea"
      },
      "source": [
        "plt.plot(x_val,y_val,'.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd6ebb56a50>]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iXktAKu9o4E"
      },
      "source": [
        "# For test ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RsLl5mF9sUG"
      },
      "source": [
        "# PtTorch`s way to generate Dataset\n",
        "from torch.utils.data import Dataset,DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhgCJUxD-CCT"
      },
      "source": [
        "class LinearData(Dataset):\n",
        "  def __init__(self,range):\n",
        "    start,end,step = range\n",
        "    self.x = torch.arange(start,end,step).float()\n",
        "    self.y = 2*self.x - 1 + 0.1 * torch.randn(len(self.x))\n",
        "    self.y = self.y.view(len(self.x),1)\n",
        "    self.input = self.x.view(len(self.x),1)\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "  \n",
        "  def __getitem__(self,idx):\n",
        "    return self.input[idx],self.y[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0gz0B8i_R9R",
        "outputId": "eca62e47-c16c-4fdd-c211-bab112b489a7"
      },
      "source": [
        "train_dataset = LinearData((0,1,0.001))\n",
        "train_dataset[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0010],\n",
              "         [0.0020],\n",
              "         [0.0030],\n",
              "         [0.0040]]), tensor([[-0.9874],\n",
              "         [-1.0807],\n",
              "         [-1.0950],\n",
              "         [-1.0610],\n",
              "         [-0.9731]]))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klPrm5Cp_eoL",
        "outputId": "f28225a5-363b-4992-b0e1-3c8cba7bc33f"
      },
      "source": [
        "train_loader = DataLoader(train_dataset,batch_size=100,shuffle=True)\n",
        "\n",
        "for x,y in train_loader:\n",
        "  print(x[:10])\n",
        "  print(y[:10])\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8370],\n",
            "        [0.3700],\n",
            "        [0.4310],\n",
            "        [0.9550],\n",
            "        [0.4540],\n",
            "        [0.0390],\n",
            "        [0.9240],\n",
            "        [0.1540],\n",
            "        [0.1670],\n",
            "        [0.2030]])\n",
            "tensor([[ 0.6172],\n",
            "        [-0.3766],\n",
            "        [ 0.0249],\n",
            "        [ 1.1506],\n",
            "        [-0.1948],\n",
            "        [-0.9171],\n",
            "        [ 0.7434],\n",
            "        [-0.8040],\n",
            "        [-0.5893],\n",
            "        [-0.7794]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTOpjWS4AsEL"
      },
      "source": [
        "val_dataset = LinearData((0,1,0.1))\n",
        "# val 은  shuffle 안하는데 성능에좋다\n",
        "val_loader = DataLoader(val_dataset,batch_size = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0v7LwxdBgni"
      },
      "source": [
        "test_dataset = LinearData((0,10,1))\n",
        "test_loader = DataLoader(test_dataset, batch_size = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMTVcDrWBvHs"
      },
      "source": [
        "# Neural Network\n",
        "class LinearNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LinearNet,self).__init__() # weight 초기화 등등 때문에 상속 받아야한다 . \n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(1,1) # input 1 , output 1\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.model(x)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbgsaQr5EIKi"
      },
      "source": [
        "net = LinearNet().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "almn71mJEuFO",
        "outputId": "c671ff14-139f-4151-b607-313fcbab35c5"
      },
      "source": [
        "criterion = nn.MSELoss(())\n",
        "optimizer = torch.optim.Adam(net.parameters(),lr=0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beg9Mv0IFc83"
      },
      "source": [
        "def train(dataloader, model, critertion, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train() \n",
        "\n",
        "  for batch, data in enumerate(dataloader):\n",
        "    X,y = data # Data in CPU \n",
        "    X,y = X.to(device), y.to(device) # to GPU\n",
        "\n",
        "    # Forward\n",
        "    out = model(X) # forward\n",
        "    loss = criterion(out,y) # Calculate loss\n",
        "\n",
        "    # Eroor backpropagation\n",
        "    optimizer.zero_grad() # Gradient 초기화\n",
        "    loss.backward() # Backward loss 계산\n",
        "    optimizer.step() # Gradient 업데이트\n",
        "    if batch % 5 == 0:\n",
        "      print(f\"#{batch} Batch : Training Loss:{loss:>8f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAVzYmOeHR--",
        "outputId": "fd653931-fc44-4925-ddd4-6c297858e44f"
      },
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "  print(f\"#{epoch} ---------------Epoch------------------------\")\n",
        "  train(train_loader,net,criterion,optimizer)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#0 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:40.568756\n",
            "#5 Batch : Training Loss:42.006401\n",
            "\n",
            "#1 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:30.717936\n",
            "#5 Batch : Training Loss:32.031059\n",
            "\n",
            "#2 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:22.017361\n",
            "#5 Batch : Training Loss:15.819109\n",
            "\n",
            "#3 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:13.214447\n",
            "#5 Batch : Training Loss:10.937173\n",
            "\n",
            "#4 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:12.029088\n",
            "#5 Batch : Training Loss:8.962704\n",
            "\n",
            "#5 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:9.632392\n",
            "#5 Batch : Training Loss:8.544584\n",
            "\n",
            "#6 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:8.469035\n",
            "#5 Batch : Training Loss:9.633257\n",
            "\n",
            "#7 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:8.316459\n",
            "#5 Batch : Training Loss:6.427209\n",
            "\n",
            "#8 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:7.979639\n",
            "#5 Batch : Training Loss:9.544440\n",
            "\n",
            "#9 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:8.946275\n",
            "#5 Batch : Training Loss:7.204777\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulbTNay9HZ9W"
      },
      "source": [
        "def val_check(dataloader, model, critertion):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.eval() # evaluation 모드 (수정 X,계산)\n",
        "\n",
        "  for batch, data in enumerate(dataloader):\n",
        "    X,y = data # Data in CPU \n",
        "    X,y = X.to(device), y.to(device) # to GPU\n",
        "\n",
        "    # Forward\n",
        "    out = model(X) # forward\n",
        "    loss = criterion(out,y) # Calculate loss\n",
        "\n",
        "\n",
        "    print(f\"Validity Loss :{loss:>8f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5Dk9aMAJ_AB",
        "outputId": "a38780b9-fdfd-42e8-8301-913065eff484"
      },
      "source": [
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "  print(f\"#{epoch} ---------------Epoch------------------------\")\n",
        "  train(train_loader,net,criterion,optimizer)\n",
        "  val_check(val_loader,net,criterion)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#0 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:6.879791\n",
            "#5 Batch : Training Loss:5.416719\n",
            "Validity Loss :0.985682\n",
            "\n",
            "#1 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:5.976114\n",
            "#5 Batch : Training Loss:5.096848\n",
            "Validity Loss :0.929561\n",
            "\n",
            "#2 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:5.848579\n",
            "#5 Batch : Training Loss:6.404454\n",
            "Validity Loss :0.875842\n",
            "\n",
            "#3 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:5.156446\n",
            "#5 Batch : Training Loss:5.351152\n",
            "Validity Loss :0.824622\n",
            "\n",
            "#4 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:5.344440\n",
            "#5 Batch : Training Loss:4.778943\n",
            "Validity Loss :0.775565\n",
            "\n",
            "#5 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:4.729265\n",
            "#5 Batch : Training Loss:3.628485\n",
            "Validity Loss :0.728379\n",
            "\n",
            "#6 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:4.490667\n",
            "#5 Batch : Training Loss:3.979174\n",
            "Validity Loss :0.683605\n",
            "\n",
            "#7 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:4.277474\n",
            "#5 Batch : Training Loss:3.843184\n",
            "Validity Loss :0.641093\n",
            "\n",
            "#8 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:3.138809\n",
            "#5 Batch : Training Loss:3.596608\n",
            "Validity Loss :0.601395\n",
            "\n",
            "#9 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:3.195058\n",
            "#5 Batch : Training Loss:3.082037\n",
            "Validity Loss :0.563641\n",
            "\n",
            "#10 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:3.311259\n",
            "#5 Batch : Training Loss:2.996809\n",
            "Validity Loss :0.529210\n",
            "\n",
            "#11 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:3.509546\n",
            "#5 Batch : Training Loss:2.423115\n",
            "Validity Loss :0.495727\n",
            "\n",
            "#12 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:2.759821\n",
            "#5 Batch : Training Loss:2.986921\n",
            "Validity Loss :0.465535\n",
            "\n",
            "#13 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:2.840254\n",
            "#5 Batch : Training Loss:3.116262\n",
            "Validity Loss :0.437008\n",
            "\n",
            "#14 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:2.350758\n",
            "#5 Batch : Training Loss:2.261792\n",
            "Validity Loss :0.411323\n",
            "\n",
            "#15 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:2.255274\n",
            "#5 Batch : Training Loss:2.287686\n",
            "Validity Loss :0.386851\n",
            "\n",
            "#16 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:2.388347\n",
            "#5 Batch : Training Loss:2.454131\n",
            "Validity Loss :0.363976\n",
            "\n",
            "#17 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:2.159307\n",
            "#5 Batch : Training Loss:2.133916\n",
            "Validity Loss :0.343297\n",
            "\n",
            "#18 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:2.077473\n",
            "#5 Batch : Training Loss:1.706995\n",
            "Validity Loss :0.324430\n",
            "\n",
            "#19 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.504058\n",
            "#5 Batch : Training Loss:1.884228\n",
            "Validity Loss :0.307265\n",
            "\n",
            "#20 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.762041\n",
            "#5 Batch : Training Loss:1.423934\n",
            "Validity Loss :0.291474\n",
            "\n",
            "#21 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.575361\n",
            "#5 Batch : Training Loss:1.679054\n",
            "Validity Loss :0.276450\n",
            "\n",
            "#22 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.386519\n",
            "#5 Batch : Training Loss:1.413241\n",
            "Validity Loss :0.263556\n",
            "\n",
            "#23 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.642400\n",
            "#5 Batch : Training Loss:1.269294\n",
            "Validity Loss :0.250964\n",
            "\n",
            "#24 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.301759\n",
            "#5 Batch : Training Loss:1.416858\n",
            "Validity Loss :0.240063\n",
            "\n",
            "#25 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.510965\n",
            "#5 Batch : Training Loss:1.344301\n",
            "Validity Loss :0.229846\n",
            "\n",
            "#26 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.306086\n",
            "#5 Batch : Training Loss:1.384534\n",
            "Validity Loss :0.221462\n",
            "\n",
            "#27 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.413865\n",
            "#5 Batch : Training Loss:1.165786\n",
            "Validity Loss :0.212717\n",
            "\n",
            "#28 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.131531\n",
            "#5 Batch : Training Loss:1.373174\n",
            "Validity Loss :0.205500\n",
            "\n",
            "#29 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.180692\n",
            "#5 Batch : Training Loss:0.939625\n",
            "Validity Loss :0.198462\n",
            "\n",
            "#30 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.216934\n",
            "#5 Batch : Training Loss:1.074435\n",
            "Validity Loss :0.191693\n",
            "\n",
            "#31 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.124103\n",
            "#5 Batch : Training Loss:1.150758\n",
            "Validity Loss :0.186594\n",
            "\n",
            "#32 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.291553\n",
            "#5 Batch : Training Loss:0.846060\n",
            "Validity Loss :0.181689\n",
            "\n",
            "#33 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.318293\n",
            "#5 Batch : Training Loss:0.883973\n",
            "Validity Loss :0.176478\n",
            "\n",
            "#34 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.178219\n",
            "#5 Batch : Training Loss:0.719591\n",
            "Validity Loss :0.171906\n",
            "\n",
            "#35 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.011422\n",
            "#5 Batch : Training Loss:1.272495\n",
            "Validity Loss :0.168433\n",
            "\n",
            "#36 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.216393\n",
            "#5 Batch : Training Loss:1.152618\n",
            "Validity Loss :0.165415\n",
            "\n",
            "#37 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.122675\n",
            "#5 Batch : Training Loss:1.046660\n",
            "Validity Loss :0.162838\n",
            "\n",
            "#38 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.944597\n",
            "#5 Batch : Training Loss:1.066597\n",
            "Validity Loss :0.159865\n",
            "\n",
            "#39 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.869879\n",
            "#5 Batch : Training Loss:0.748654\n",
            "Validity Loss :0.157166\n",
            "\n",
            "#40 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.163921\n",
            "#5 Batch : Training Loss:1.002518\n",
            "Validity Loss :0.154840\n",
            "\n",
            "#41 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.001476\n",
            "#5 Batch : Training Loss:1.251378\n",
            "Validity Loss :0.151782\n",
            "\n",
            "#42 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.983066\n",
            "#5 Batch : Training Loss:1.014922\n",
            "Validity Loss :0.150331\n",
            "\n",
            "#43 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.975752\n",
            "#5 Batch : Training Loss:1.046183\n",
            "Validity Loss :0.149520\n",
            "\n",
            "#44 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.823149\n",
            "#5 Batch : Training Loss:0.754407\n",
            "Validity Loss :0.147745\n",
            "\n",
            "#45 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.984607\n",
            "#5 Batch : Training Loss:1.040087\n",
            "Validity Loss :0.146464\n",
            "\n",
            "#46 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.066067\n",
            "#5 Batch : Training Loss:1.028527\n",
            "Validity Loss :0.144685\n",
            "\n",
            "#47 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.910889\n",
            "#5 Batch : Training Loss:0.897981\n",
            "Validity Loss :0.143974\n",
            "\n",
            "#48 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.851259\n",
            "#5 Batch : Training Loss:0.892242\n",
            "Validity Loss :0.142480\n",
            "\n",
            "#49 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.854287\n",
            "#5 Batch : Training Loss:0.924372\n",
            "Validity Loss :0.141604\n",
            "\n",
            "#50 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.151507\n",
            "#5 Batch : Training Loss:0.957202\n",
            "Validity Loss :0.140550\n",
            "\n",
            "#51 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.009800\n",
            "#5 Batch : Training Loss:1.031945\n",
            "Validity Loss :0.140546\n",
            "\n",
            "#52 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.094788\n",
            "#5 Batch : Training Loss:1.044391\n",
            "Validity Loss :0.140574\n",
            "\n",
            "#53 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.792227\n",
            "#5 Batch : Training Loss:0.931309\n",
            "Validity Loss :0.138670\n",
            "\n",
            "#54 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.026198\n",
            "#5 Batch : Training Loss:0.866878\n",
            "Validity Loss :0.138259\n",
            "\n",
            "#55 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.991149\n",
            "#5 Batch : Training Loss:0.924617\n",
            "Validity Loss :0.137528\n",
            "\n",
            "#56 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.936533\n",
            "#5 Batch : Training Loss:1.000948\n",
            "Validity Loss :0.138757\n",
            "\n",
            "#57 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.027732\n",
            "#5 Batch : Training Loss:1.144206\n",
            "Validity Loss :0.136891\n",
            "\n",
            "#58 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.074553\n",
            "#5 Batch : Training Loss:1.093455\n",
            "Validity Loss :0.136554\n",
            "\n",
            "#59 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.041840\n",
            "#5 Batch : Training Loss:0.903290\n",
            "Validity Loss :0.136352\n",
            "\n",
            "#60 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.984080\n",
            "#5 Batch : Training Loss:0.977980\n",
            "Validity Loss :0.135596\n",
            "\n",
            "#61 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.831172\n",
            "#5 Batch : Training Loss:0.994983\n",
            "Validity Loss :0.136730\n",
            "\n",
            "#62 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.956931\n",
            "#5 Batch : Training Loss:1.136435\n",
            "Validity Loss :0.136696\n",
            "\n",
            "#63 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.292887\n",
            "#5 Batch : Training Loss:0.980320\n",
            "Validity Loss :0.134753\n",
            "\n",
            "#64 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.851954\n",
            "#5 Batch : Training Loss:1.173272\n",
            "Validity Loss :0.135943\n",
            "\n",
            "#65 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.136653\n",
            "#5 Batch : Training Loss:0.737843\n",
            "Validity Loss :0.135573\n",
            "\n",
            "#66 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.860496\n",
            "#5 Batch : Training Loss:0.929591\n",
            "Validity Loss :0.134367\n",
            "\n",
            "#67 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.937749\n",
            "#5 Batch : Training Loss:0.994715\n",
            "Validity Loss :0.134916\n",
            "\n",
            "#68 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.872760\n",
            "#5 Batch : Training Loss:1.161490\n",
            "Validity Loss :0.135579\n",
            "\n",
            "#69 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.873942\n",
            "#5 Batch : Training Loss:0.975349\n",
            "Validity Loss :0.134405\n",
            "\n",
            "#70 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.926142\n",
            "#5 Batch : Training Loss:0.932705\n",
            "Validity Loss :0.134376\n",
            "\n",
            "#71 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.996670\n",
            "#5 Batch : Training Loss:0.964176\n",
            "Validity Loss :0.134956\n",
            "\n",
            "#72 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.057215\n",
            "#5 Batch : Training Loss:1.038062\n",
            "Validity Loss :0.134262\n",
            "\n",
            "#73 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.989640\n",
            "#5 Batch : Training Loss:1.068068\n",
            "Validity Loss :0.134856\n",
            "\n",
            "#74 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.018456\n",
            "#5 Batch : Training Loss:1.017290\n",
            "Validity Loss :0.134422\n",
            "\n",
            "#75 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.751925\n",
            "#5 Batch : Training Loss:0.988087\n",
            "Validity Loss :0.134746\n",
            "\n",
            "#76 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.873571\n",
            "#5 Batch : Training Loss:1.171269\n",
            "Validity Loss :0.134981\n",
            "\n",
            "#77 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.859728\n",
            "#5 Batch : Training Loss:0.942942\n",
            "Validity Loss :0.133276\n",
            "\n",
            "#78 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.067230\n",
            "#5 Batch : Training Loss:1.099621\n",
            "Validity Loss :0.135290\n",
            "\n",
            "#79 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.911719\n",
            "#5 Batch : Training Loss:1.109189\n",
            "Validity Loss :0.135620\n",
            "\n",
            "#80 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.010221\n",
            "#5 Batch : Training Loss:0.805492\n",
            "Validity Loss :0.133020\n",
            "\n",
            "#81 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.152881\n",
            "#5 Batch : Training Loss:1.168583\n",
            "Validity Loss :0.133966\n",
            "\n",
            "#82 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.872729\n",
            "#5 Batch : Training Loss:0.944155\n",
            "Validity Loss :0.134614\n",
            "\n",
            "#83 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.766906\n",
            "#5 Batch : Training Loss:0.895774\n",
            "Validity Loss :0.135854\n",
            "\n",
            "#84 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.220376\n",
            "#5 Batch : Training Loss:0.842586\n",
            "Validity Loss :0.134202\n",
            "\n",
            "#85 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.850135\n",
            "#5 Batch : Training Loss:1.065063\n",
            "Validity Loss :0.132856\n",
            "\n",
            "#86 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.342505\n",
            "#5 Batch : Training Loss:0.875748\n",
            "Validity Loss :0.133546\n",
            "\n",
            "#87 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.864096\n",
            "#5 Batch : Training Loss:0.913208\n",
            "Validity Loss :0.135836\n",
            "\n",
            "#88 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.981117\n",
            "#5 Batch : Training Loss:0.935277\n",
            "Validity Loss :0.134273\n",
            "\n",
            "#89 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.976395\n",
            "#5 Batch : Training Loss:0.951875\n",
            "Validity Loss :0.134847\n",
            "\n",
            "#90 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.971363\n",
            "#5 Batch : Training Loss:0.915883\n",
            "Validity Loss :0.132898\n",
            "\n",
            "#91 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.825399\n",
            "#5 Batch : Training Loss:1.330988\n",
            "Validity Loss :0.135633\n",
            "\n",
            "#92 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.753426\n",
            "#5 Batch : Training Loss:0.889806\n",
            "Validity Loss :0.134285\n",
            "\n",
            "#93 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.036476\n",
            "#5 Batch : Training Loss:0.942612\n",
            "Validity Loss :0.134201\n",
            "\n",
            "#94 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.837650\n",
            "#5 Batch : Training Loss:1.065964\n",
            "Validity Loss :0.132951\n",
            "\n",
            "#95 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.014714\n",
            "#5 Batch : Training Loss:0.821242\n",
            "Validity Loss :0.134107\n",
            "\n",
            "#96 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.969749\n",
            "#5 Batch : Training Loss:1.022478\n",
            "Validity Loss :0.135427\n",
            "\n",
            "#97 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:0.855896\n",
            "#5 Batch : Training Loss:0.858469\n",
            "Validity Loss :0.134529\n",
            "\n",
            "#98 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.066944\n",
            "#5 Batch : Training Loss:0.808587\n",
            "Validity Loss :0.133646\n",
            "\n",
            "#99 ---------------Epoch------------------------\n",
            "#0 Batch : Training Loss:1.052907\n",
            "#5 Batch : Training Loss:0.826014\n",
            "Validity Loss :0.133550\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Ju2N0DRyKEWt",
        "outputId": "3779498e-cd59-448e-f777-1634e530546c"
      },
      "source": [
        "for X,y in test_loader:\n",
        "  X_gpu = X.float().to(device)\n",
        "  x = X\n",
        "  out = net(X_gpu).cpu().detach()  # matplotlib를 사용하기 위해서는 CPU여야만 한다 / detach()는 tensor -> array로 바꿔줌\n",
        "\n",
        "  plt.plot(x,y,'.',label=\"Original Data\")\n",
        "  plt.plot(x,out,label=\"LinearNet\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUMQO3dMOXRS",
        "outputId": "6f21e83f-cf95-435d-98a0-e1d70410d3d8"
      },
      "source": [
        "for param in net.parameters():\n",
        "  print(param[:])\n",
        "  # torch 자체에도 bias가 있어서 따로 안넣어도 되었다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.9824]], device='cuda:0', grad_fn=<SliceBackward>)\n",
            "tensor([-0.9902], device='cuda:0', grad_fn=<SliceBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQS_ORI8PtKh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}